{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18064200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "lucene_lib = \"lucene-9.8.0\"\n",
    "tantivy_lib = \"tantivy-0.21\"\n",
    "metric_label_microsec=\"(Î¼s)\"\n",
    "\n",
    "results_location = \"../web/build/results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare mean between tantivy and lucene durations\n",
    "def get_mean_per_query_compare(test_type, library):\n",
    "    results=json.load(open(results_location, \"r\"))\n",
    "    df = results[test_type][library]\n",
    "    df = pd.json_normalize(df)\n",
    "    df = df.drop(\"tags\", axis=1)\n",
    "    df1 = pd.concat([pd.DataFrame(df[\"duration\"].values.tolist())], \n",
    "             axis=1, \n",
    "             keys=df.columns)\n",
    "    df1.columns = [f'{i}{j}' for i, j in df1.columns]\n",
    "    df[f\"{library}{metric_label_microsec}\"] = df1.mean(axis=1)\n",
    "    df = df.drop([\"duration\",\"count\"], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucene_df = get_mean_per_query_compare(\"TOP_100\", lucene_lib)\n",
    "tantivy_df = get_mean_per_query_compare(\"TOP_100\", tantivy_lib)\n",
    "df = lucene_df.merge(tantivy_df, on=\"query\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e75878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff\"] = df[f\"{lucene_lib}{metric_label_microsec}\"] - df[f\"{tantivy_lib}{metric_label_microsec}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70abd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"diff\"]<0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_per_query(test_type, library):\n",
    "    results=json.load(open(results_location, \"r\"))\n",
    "    df = results[test_type][library]\n",
    "    df = pd.json_normalize(df)\n",
    "    df = df.drop(\"tags\", axis=1)\n",
    "    df1 = pd.concat([pd.DataFrame(df[\"duration\"].values.tolist())], \n",
    "             axis=1, \n",
    "             keys=df.columns)\n",
    "    df1.columns = [f'{i}{j}' for i, j in df1.columns]\n",
    "    df[f\"meanDuration{metric_label_microsec}\"] = df1.mean(axis=1)\n",
    "    df = df.drop([\"duration\",\"count\"], axis=1)\n",
    "    df[\"library\"] = library\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5583bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# started with this, but doesn't work as well as get_mean_per_query_compare for what I was doing\n",
    "get_mean_per_query(\"TOP_100\", lucene_lib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
